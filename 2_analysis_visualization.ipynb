{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Analysis and Visualization\n",
    "\n",
    "This notebook integrates the analysis and visualization of four experiments: WSLS vs Baseline, Feedback vs Baseline, Payoff vs Baseline, and WSLS vs Payoff.\n",
    "\n",
    "To run this notebook, ensure you have the following R packages installed:\n",
    "- `tidyverse`\n",
    "- `ggpubr`\n",
    "- `dplyr`\n",
    "\n",
    "Also, make sure all data files (e.g., `baseline_allresult_processed.csv`) are in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "library(tidyverse)\n",
    "library(ggpubr)\n",
    "library(dplyr)\n",
    "\n",
    "# Define a common Wilcoxon test function for multiple uses\n",
    "wilcox_test <- function(x, y, alternative) {\n",
    "  test <- wilcox.test(x, y, alternative = alternative)\n",
    "  return(test$p.value)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: WSLS vs Baseline Analysis\n",
    "\n",
    "This section compares the WSLS strategy against the Baseline, analyzing schema selection, reaction times, observation counts, attention shifts, performance, and accuracy distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "baseline_data_wsls <- read_csv(\"baseline_allresult_processed.csv\")\n",
    "WSLS_data <- read_csv(\"WSLS_allresult_processed.csv\")\n",
    "baseline_data_wsls$group <- \"Baseline\"\n",
    "WSLS_data$group <- \"WSLS\"\n",
    "all_data_wsls <- bind_rows(baseline_data_wsls, WSLS_data) %>%\n",
    "  mutate(Subject = paste0(group, \"_\", Subject)) %>%\n",
    "  arrange(Subject, Round, Phase)\n",
    "\n",
    "# Panel A: Distribution of Consecutive Schema Selections (Histogram with p-value, complete Baseline)\n",
    "streak_data <- all_data_wsls %>%\n",
    "  group_by(Subject, Round) %>%\n",
    "  summarise(Schema_Phase1 = first(Schema), Schema_Phase2 = last(Schema), group = first(group)) %>%\n",
    "  arrange(Subject, Round) %>%\n",
    "  group_by(Subject) %>%\n",
    "  mutate(\n",
    "    is_continuous = (Schema_Phase1 == lag(Schema_Phase1, default = NA) |\n",
    "                       Schema_Phase1 == lag(Schema_Phase2, default = NA) |\n",
    "                       Schema_Phase2 == lag(Schema_Phase1, default = NA) |\n",
    "                       Schema_Phase2 == lag(Schema_Phase2, default = NA)),\n",
    "    streak_start = !is_continuous | is.na(is_continuous),\n",
    "    streak_id = cumsum(streak_start)\n",
    "  ) %>%\n",
    "  group_by(Subject, streak_id) %>%\n",
    "  summarise(streak_length = n(), group = first(group)) %>%\n",
    "  ungroup()\n",
    "streak_freq <- streak_data %>%\n",
    "  group_by(group, streak_length) %>%\n",
    "  summarise(count = n(), .groups = \"drop\") %>%\n",
    "  complete(group, streak_length = 1:max(streak_length), fill = list(count = 0))\n",
    "baseline_streaks <- streak_data %>% filter(group == \"Baseline\") %>% pull(streak_length)\n",
    "wsls_streaks <- streak_data %>% filter(group == \"WSLS\") %>% pull(streak_length)\n",
    "ks_result <- ks.test(baseline_streaks, wsls_streaks)\n",
    "p_value <- ks_result$p.value\n",
    "p_label <- ifelse(p_value < 0.001, \"p < 0.001\", sprintf(\"p = %.3f\", p_value))\n",
    "p1 <- ggplot(streak_freq, aes(x = streak_length, y = count, fill = group)) +\n",
    "  geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "  scale_fill_manual(values = c(\"Baseline\" = \"#1F77B4\", \"WSLS\" = \"#FF7F0E\")) +\n",
    "  labs(title = \"Sequential Schema Selection in WSLS\", x = \"Consecutive Number\", y = \"Sequence Number\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\")) +\n",
    "  annotate(\"text\", x = Inf, y = Inf, label = p_label, hjust = 1.1, vjust = 1.1, size = 4)\n",
    "\n",
    "# Display the plot\n",
    "print(p1)\n",
    "ggsave(\"Sequential_schema_WSLSvsBaseline.png\", p1, width = 5, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSLS Classification and Comparison with Baseline\n",
    "wsls_classified <- WSLS_data %>%\n",
    "  arrange(Subject, Round, Phase) %>%\n",
    "  group_by(Subject) %>%\n",
    "  mutate(\n",
    "    prev_Schema1 = lag(Schema, n = 2, default = NA),\n",
    "    prev_Schema2 = lag(Schema, n = 1, default = NA),\n",
    "    prev_AC1 = lag(AC, n = 2, default = NA),\n",
    "    prev_AC2 = lag(AC, n = 1, default = NA)\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    same_schema = (Schema == prev_Schema1 | Schema == prev_Schema2),\n",
    "    prev_AC = case_when(\n",
    "      Schema == prev_Schema1 & Schema != prev_Schema2 ~ prev_AC1,\n",
    "      Schema == prev_Schema2 & Schema != prev_Schema1 ~ prev_AC2,\n",
    "      Schema == prev_Schema1 & Schema == prev_Schema2 ~ pmax(prev_AC1, prev_AC2, na.rm = TRUE),\n",
    "      TRUE ~ NA_real_\n",
    "    ),\n",
    "    prev_AC_no_match = ifelse(same_schema, NA_real_, prev_AC2),\n",
    "    condition = case_when(\n",
    "      is.na(prev_Schema1) | is.na(prev_Schema2) ~ NA_character_,\n",
    "      same_schema & prev_AC == 1 ~ \"Same, AC=1\",\n",
    "      same_schema & prev_AC != 1 ~ \"Same, AC!=1\",\n",
    "      !same_schema & prev_AC_no_match == 1 ~ \"Diff, AC=1\",\n",
    "      !same_schema & prev_AC_no_match != 1 ~ \"Diff, AC!=1\"\n",
    "    )\n",
    "  ) %>%\n",
    "  ungroup()\n",
    "\n",
    "# Combine WSLS and Baseline data\n",
    "analysis_data <- bind_rows(\n",
    "  wsls_classified %>% select(condition, Schema_RT, Schema_OB, Schema_AS) %>% filter(!is.na(condition)),\n",
    "  baseline_data_wsls %>% mutate(condition = \"Baseline\") %>% select(condition, Schema_RT, Schema_OB, Schema_AS)\n",
    ") %>%\n",
    "  filter(!is.na(Schema_RT), !is.na(Schema_OB), !is.na(Schema_AS))\n",
    "\n",
    "# Verify group sizes\n",
    "print(analysis_data %>% group_by(condition) %>% summarise(n = n()))\n",
    "\n",
    "# Panel B: Violin Plot for Schema_RT\n",
    "p2 <- ggplot(analysis_data, aes(x = condition, y = Schema_RT, fill = condition)) +\n",
    "  geom_violin(trim = TRUE) +\n",
    "  scale_fill_manual(values = c(\"Same, AC=1\" = \"#FF7F0E\", \"Same, AC!=1\" = \"#D62728\", \n",
    "                               \"Diff, AC=1\" = \"#2CA02C\", \"Diff, AC!=1\" = \"#9467BD\", \n",
    "                               \"Baseline\" = \"#1F77B4\")) +\n",
    "  labs(title = \"Schema Reaction Times in WSLS\", x = \"Condition\", y = \"Schema Reaction Time (s)\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Kruskal-Wallis test and add p-value\n",
    "kruskal_result_rt <- kruskal.test(Schema_RT ~ condition, data = analysis_data)\n",
    "p_value_rt <- kruskal_result_rt$p.value\n",
    "p_label_rt <- ifelse(p_value_rt < 0.001, \"p < 0.001\", sprintf(\"p = %.3f\", p_value_rt))\n",
    "p2 <- p2 + annotate(\"text\", x = Inf, y = Inf, label = p_label_rt, hjust = 1.1, vjust = 1.1, size = 4)\n",
    "\n",
    "# Display the plot\n",
    "print(p2)\n",
    "ggsave(\"Schema_RT_WSLSvsBaseline.png\", p2, width = 5, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel C: Violin Plot for Schema_OB\n",
    "p3 <- ggplot(analysis_data, aes(x = condition, y = Schema_OB, fill = condition)) +\n",
    "  geom_violin(trim = TRUE) +\n",
    "  scale_fill_manual(values = c(\"Same, AC=1\" = \"#FF7F0E\", \"Same, AC!=1\" = \"#D62728\", \n",
    "                               \"Diff, AC=1\" = \"#2CA02C\", \"Diff, AC!=1\" = \"#9467BD\", \n",
    "                               \"Baseline\" = \"#1F77B4\")) +\n",
    "  labs(title = \"Schema Observation Counts in WSLS\", x = \"Condition\", y = \"Schema Observation Counts\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Kruskal-Wallis test and add p-value\n",
    "kruskal_result_ob <- kruskal.test(Schema_OB ~ condition, data = analysis_data)\n",
    "p_value_ob <- kruskal_result_ob$p.value\n",
    "p_label_ob <- ifelse(p_value_ob < 0.001, \"p < 0.001\", sprintf(\"p = %.3f\", p_value_ob))\n",
    "p3 <- p3 + annotate(\"text\", x = Inf, y = Inf, label = p_label_ob, hjust = 1.1, vjust = 1.1, size = 4)\n",
    "\n",
    "# Display the plot\n",
    "print(p3)\n",
    "ggsave(\"Schema_OB_analysis_WSLSvsBaseline.png\", p3, width = 5, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel D: Violin Plot for Schema_AS\n",
    "p4 <- ggplot(analysis_data, aes(x = condition, y = Schema_AS, fill = condition)) +\n",
    "  geom_violin(trim = TRUE) +\n",
    "  scale_fill_manual(values = c(\"Same, AC=1\" = \"#FF7F0E\", \"Same, AC!=1\" = \"#D62728\", \n",
    "                               \"Diff, AC=1\" = \"#2CA02C\", \"Diff, AC!=1\" = \"#9467BD\", \n",
    "                               \"Baseline\" = \"#1F77B4\")) +\n",
    "  labs(title = \"Schema Attention Shifts in WSLS\", x = \"Condition\", y = \"Schema Attention Shifts\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Kruskal-Wallis test and add p-value\n",
    "kruskal_result_as <- kruskal.test(Schema_AS ~ condition, data = analysis_data)\n",
    "p_value_as <- kruskal_result_as$p.value\n",
    "p_label_as <- ifelse(p_value_as < 0.001, \"p < 0.001\", sprintf(\"p = %.3f\", p_value_as))\n",
    "p4 <- p4 + annotate(\"text\", x = Inf, y = Inf, label = p_label_as, hjust = 1.1, vjust = 1.1, size = 4)\n",
    "\n",
    "# Display the plot\n",
    "print(p4)\n",
    "ggsave(\"Schema_AS_analysis_WSLSvsBaseline.png\", p4, width = 5, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel E: Average Performance Per Round\n",
    "performance_by_round_wsls <- all_data_wsls %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_performance = mean(performance, na.rm = TRUE),\n",
    "    se_performance = sd(performance, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p5 <- ggplot(performance_by_round_wsls, aes(x = Round, y = mean_performance, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_performance - se_performance, ymax = mean_performance + se_performance), alpha = 0.2, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline\" = \"#1F77B4\", \"WSLS\" = \"#FF7F0E\")) +\n",
    "  labs(title = \"Average Performance For Each Round\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Two-sided Wilcoxon test for performance differences vs Baseline\n",
    "baseline_performance_wsls <- all_data_wsls %>% filter(group == \"Baseline\") %>% select(performance)\n",
    "WSLS_performance <- all_data_wsls %>% filter(group == \"WSLS\") %>% select(performance)\n",
    "p_WSLS <- wilcox_test(WSLS_performance$performance, baseline_performance_wsls$performance, \"two.sided\")\n",
    "cat(\"WSLS vs Baseline (two-sided test): p =\", p_WSLS, \"\\n\")\n",
    "\n",
    "# Display the plot\n",
    "print(p5)\n",
    "ggsave(\"Perform_WSLSvsBaseline.png\", p5, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel F: AC Distribution Per Round (Bubble Plot)\n",
    "ac_freq_wsls <- all_data_wsls %>%\n",
    "  group_by(group, Round, AC) %>%\n",
    "  summarise(count = n(), .groups = \"drop\") %>%\n",
    "  filter(!is.na(AC))\n",
    "p6 <- ggplot(ac_freq_wsls, aes(x = Round, y = AC, size = count, color = group)) +\n",
    "  geom_point(position = position_dodge(width = 0.8), alpha = 0.7) +\n",
    "  scale_size_continuous(range = c(2, 10)) +\n",
    "  scale_color_manual(values = c(\"Baseline\" = \"#1F77B4\", \"WSLS\" = \"#FF7F0E\")) +\n",
    "  labs(title = \"Accuracy Distribution (WSLS vs Baseline)\", x = \"Round\", y = \"Schema Accuracy\", size = \"Number\", color = \"Group\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p6)\n",
    "ggsave(\"AC_WSLSvsBaseline.png\", p6, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine violin plots into a single figure\n",
    "long_data <- analysis_data %>%\n",
    "  pivot_longer(\n",
    "    cols = c(Schema_RT, Schema_OB, Schema_AS),\n",
    "    names_to = \"metric\",\n",
    "    values_to = \"value\"\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    metric = factor(metric, \n",
    "                    levels = c(\"Schema_RT\", \"Schema_OB\", \"Schema_AS\"),\n",
    "                    labels = c(\"Reaction Time (s)\", \"Observation Counts\", \"Attention Shifts\"))\n",
    "  )\n",
    "\n",
    "y_limits <- long_data %>%\n",
    "  group_by(metric) %>%\n",
    "  summarise(\n",
    "    min_val = min(value, na.rm = TRUE),\n",
    "    max_val = max(value, na.rm = TRUE),\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    y_min = pmax(0, min_val - 0.1 * (max_val - min_val)),\n",
    "    y_max = max_val + 0.1 * (max_val - min_val)\n",
    "  )\n",
    "\n",
    "combined_violin <- ggplot(long_data, aes(x = condition, y = value, fill = condition)) +\n",
    "  geom_violin(trim = TRUE) +\n",
    "  scale_fill_manual(values = c(\"Same, AC=1\" = \"#FF7F0E\", \"Same, AC!=1\" = \"#D62728\", \n",
    "                               \"Diff, AC=1\" = \"#2CA02C\", \"Diff, AC!=1\" = \"#9467BD\", \n",
    "                               \"Baseline\" = \"#1F77B4\")) +\n",
    "  facet_wrap(~ metric, scales = \"free_y\", ncol = 1) +\n",
    "  labs(title = \"Schema Performance Metrics\", x = \"Condition\", y = NULL) +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(\n",
    "    legend.position = \"top\",\n",
    "    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n",
    "    strip.text = element_text(size = 12, face = \"bold\"),\n",
    "    axis.text.x = element_text(angle = 45, hjust = 1)\n",
    "  )\n",
    "\n",
    "kw_tests <- long_data %>%\n",
    "  group_by(metric) %>%\n",
    "  summarise(\n",
    "    p_value = kruskal.test(value ~ condition)$p.value,\n",
    "    .groups = \"drop\"\n",
    "  ) %>%\n",
    "  mutate(\n",
    "    p_label = ifelse(p_value < 0.001, \"p < 0.001\", sprintf(\"p = %.3f\", p_value)),\n",
    "    y_pos = y_limits$y_max[match(metric, y_limits$metric)]\n",
    "  )\n",
    "\n",
    "combined_violin <- combined_violin +\n",
    "  geom_text(\n",
    "    data = kw_tests,\n",
    "    aes(x = Inf, y = y_pos, label = p_label),\n",
    "    hjust = 1.1, vjust = 1.1, size = 3.5,\n",
    "    inherit.aes = FALSE\n",
    "  )\n",
    "\n",
    "# Display the plot\n",
    "print(combined_violin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all plots for WSLS vs Baseline\n",
    "combined_plot_wsls <- ggarrange(p1, p2, p3, p4, p5, p6,\n",
    "                                labels = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"),\n",
    "                                ncol = 2, nrow = 3,\n",
    "                                heights = c(1, 1, 1),\n",
    "                                common.legend = FALSE)\n",
    "ggsave(\"combined_analysis_WSLSvsBaseline.png\", combined_plot_wsls, width = 10, height = 12, dpi = 300)\n",
    "\n",
    "# Display the combined plot\n",
    "print(combined_plot_wsls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feedback vs Baseline Analysis\n",
    "\n",
    "This section analyzes the impact of emotional feedback (Feedback, Excitement, Depression) on performance and reaction times compared to the Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "baseline_data_feedback <- read_csv(\"baseline_allresult_processed.csv\")\n",
    "feedback_data <- read_csv(\"feedback_allresult_processed.csv\")\n",
    "excitement_data <- read_csv(\"excitement_allresult_processed.csv\")\n",
    "depression_data <- read_csv(\"depression_allresult_processed.csv\")\n",
    "baseline_data_feedback$group <- \"Baseline\"\n",
    "feedback_data$group <- \"Feedback\"\n",
    "excitement_data$group <- \"Excitement\"\n",
    "depression_data$group <- \"Depression\"\n",
    "all_data_feedback <- bind_rows(baseline_data_feedback, feedback_data, excitement_data, depression_data) %>%\n",
    "  mutate(Subject = paste0(group, \"_\", Subject)) %>%\n",
    "  arrange(Subject, Round, Phase)\n",
    "\n",
    "# Panel A: Average Performance Per Round\n",
    "performance_by_round_feedback <- all_data_feedback %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_performance = mean(performance, na.rm = TRUE),\n",
    "    se_performance = sd(performance, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p7 <- ggplot(performance_by_round_feedback, aes(x = Round, y = mean_performance, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_performance - se_performance, ymax = mean_performance + se_performance), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline\" = \"#1F77B4\", \"Feedback\" = \"#FF7F0E\", \"Depression\" = \"#2CA02C\", \"Excitement\" = \"#D62728\")) +\n",
    "  labs(title = \"Average Performance For Each Round\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p7)\n",
    "ggsave(\"perform_FeedbackvsBaseline.png\", p7, width = 7, height = 6, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel B: Violin Plot Comparing Reaction Times Across Groups\n",
    "p8 <- ggplot(all_data_feedback, aes(x = group, y = Schema_RT, fill = group)) +\n",
    "  geom_violin(trim = TRUE) +\n",
    "  scale_fill_manual(values = c(\"Baseline\" = \"#1F77B4\", \"Feedback\" = \"#FF7F0E\", \"Depression\" = \"#2CA02C\", \"Excitement\" = \"#D62728\")) +\n",
    "  labs(title = \"Reaction Times under Different Emotional Feedback\", x = \"Emotion Group\", y = \"Schema Reaction Time (s)\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Kruskal-Wallis test and add p-value\n",
    "kruskal_result_rt_feedback <- kruskal.test(Schema_RT ~ group, data = all_data_feedback)\n",
    "p_value_rt_feedback <- kruskal_result_rt_feedback$p.value\n",
    "p_label_rt_feedback <- ifelse(p_value_rt_feedback < 0.001, \"p < 0.001\", sprintf(\"p = %.3f\", p_value_rt_feedback))\n",
    "p8 <- p8 + annotate(\"text\", x = Inf, y = Inf, label = p_label_rt_feedback, hjust = 1.1, vjust = 1.1, size = 4)\n",
    "\n",
    "# Display the plot\n",
    "print(p8)\n",
    "ggsave(\"reaction_time_FeedbackvsBaseline.png\", p8, width = 5, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel C: Average Emotional Factor Per Round\n",
    "emotion_factor_by_round <- all_data_feedback %>%\n",
    "  filter(Round <= 6) %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_emotion_factor = mean(emotion_factor, na.rm = TRUE),\n",
    "    se_emotion_factor = sd(emotion_factor, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p9 <- ggplot(emotion_factor_by_round, aes(x = Round, y = mean_emotion_factor, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_emotion_factor - se_emotion_factor, ymax = mean_emotion_factor + se_emotion_factor), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline\" = \"#1F77B4\", \"Feedback\" = \"#FF7F0E\", \"Depression\" = \"#2CA02C\", \"Excitement\" = \"#D62728\")) +\n",
    "  labs(title = \"Average Emotional Factor For Each Round\", x = \"Round\", y = \"Average Emotional Factor\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel D: Dual-Axis Plot (Performance and Emotional Factor)\n",
    "p10 <- ggplot() +\n",
    "  geom_line(data = performance_by_round_feedback, aes(x = Round, y = mean_performance, color = group), size = 1) +\n",
    "  geom_ribbon(data = performance_by_round_feedback, aes(x = Round, ymin = mean_performance - se_performance, ymax = mean_performance + se_performance, fill = group), alpha = 0.08, linetype = 0) +\n",
    "  geom_line(data = emotion_factor_by_round, aes(x = Round, y = mean_emotion_factor * 10, color = group), linetype = \"dashed\", size = 1) +\n",
    "  geom_ribbon(data = emotion_factor_by_round, aes(x = Round, ymin = (mean_emotion_factor - se_emotion_factor) * 10, ymax = (mean_emotion_factor + se_emotion_factor) * 10, fill = group), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline\" = \"#1F77B4\", \"Feedback\" = \"#FF7F0E\", \"Depression\" = \"#2CA02C\", \"Excitement\" = \"#D62728\")) +\n",
    "  scale_fill_manual(values = c(\"Baseline\" = \"#1F77B4\", \"Feedback\" = \"#FF7F0E\", \"Depression\" = \"#2CA02C\", \"Excitement\" = \"#D62728\")) +\n",
    "  labs(title = \"Average Performance and Emotional Changes\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\")) +\n",
    "  theme(axis.title.y = element_text(color = \"black\")) +\n",
    "  scale_y_continuous(sec.axis = sec_axis(~ . / 10, name = \"Average Emotional Factor\")) +\n",
    "  theme(axis.title.y.right = element_text(color = \"black\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p10)\n",
    "ggsave(\"combined_performance_emotion.png\", p10, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare reaction times of each group with Baseline\n",
    "baseline_rt <- all_data_feedback %>% filter(group == \"Baseline\") %>% select(Schema_RT)\n",
    "feedback_rt <- all_data_feedback %>% filter(group == \"Feedback\") %>% select(Schema_RT)\n",
    "excitement_rt <- all_data_feedback %>% filter(group == \"Excitement\") %>% select(Schema_RT)\n",
    "depression_rt <- all_data_feedback %>% filter(group == \"Depression\") %>% select(Schema_RT)\n",
    "\n",
    "p_feedback_rt <- wilcox_test(feedback_rt$Schema_RT, baseline_rt$Schema_RT, \"two.sided\")\n",
    "p_excitement_rt <- wilcox_test(excitement_rt$Schema_RT, baseline_rt$Schema_RT, \"less\")\n",
    "p_depression_rt <- wilcox_test(depression_rt$Schema_RT, baseline_rt$Schema_RT, \"greater\")\n",
    "\n",
    "cat(\"Baseline vs Feedback (two-sided test, reaction time): p =\", p_feedback_rt, \"\\n\")\n",
    "cat(\"Baseline vs Excitement (one-tailed test, reaction time > Baseline): p =\", p_excitement_rt, \"\\n\")\n",
    "cat(\"Baseline vs Depression (one-tailed test, reaction time < Baseline): p =\", p_depression_rt, \"\\n\")\n",
    "\n",
    "# Compare performance of each group with Baseline\n",
    "baseline_performance_feedback <- all_data_feedback %>% filter(group == \"Baseline\") %>% select(performance)\n",
    "feedback_performance <- all_data_feedback %>% filter(group == \"Feedback\") %>% select(performance)\n",
    "excitement_performance <- all_data_feedback %>% filter(group == \"Excitement\") %>% select(performance)\n",
    "depression_performance <- all_data_feedback %>% filter(group == \"Depression\") %>% select(performance)\n",
    "\n",
    "p_feedback <- wilcox_test(feedback_performance$performance, baseline_performance_feedback$performance, \"two.sided\")\n",
    "p_excitement <- wilcox_test(excitement_performance$performance, baseline_performance_feedback$performance, \"greater\")\n",
    "p_depression <- wilcox_test(depression_performance$performance, baseline_performance_feedback$performance, \"greater\")\n",
    "\n",
    "cat(\"Baseline vs Feedback (two-sided test, performance): p =\", p_feedback, \"\\n\")\n",
    "cat(\"Baseline vs Excitement (one-tailed test, performance > Baseline): p =\", p_excitement, \"\\n\")\n",
    "cat(\"Baseline vs Depression (one-tailed test, performance > Baseline): p =\", p_depression, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine plots for Feedback vs Baseline\n",
    "combined_plot_feedback <- ggarrange(p7, p8, p10,\n",
    "                                    labels = c(\"A\", \"B\", \"C\"),\n",
    "                                    ncol = 3, nrow = 1,\n",
    "                                    heights = c(1, 1, 1),\n",
    "                                    common.legend = FALSE)\n",
    "ggsave(\"combined_analysis_FeedbackvsBaseline.png\", combined_plot_feedback, width = 15, height = 6, dpi = 300)\n",
    "\n",
    "# Display the combined plot\n",
    "print(combined_plot_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Payoff vs Baseline Analysis\n",
    "\n",
    "This section compares the Payoff strategy against the Baseline over 1500s and 2500s, focusing on performance and accuracy distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "baseline_1500s_data_payoff <- read_csv(\"baseline_1500s_allresult_processed.csv\")\n",
    "baseline_2500s_data_payoff <- read_csv(\"baseline_2500s_allresult_processed.csv\")\n",
    "payoff_1500s_data <- read_csv(\"payoff_1500s_allresult_processed.csv\")\n",
    "payoff_2500s_data <- read_csv(\"payoff_2500s_allresult_processed.csv\")\n",
    "\n",
    "baseline_1500s_data_payoff <- baseline_1500s_data_payoff %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "baseline_2500s_data_payoff <- baseline_2500s_data_payoff %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "payoff_1500s_data <- payoff_1500s_data %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "payoff_2500s_data <- payoff_2500s_data %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "\n",
    "baseline_1500s_data_payoff$group <- \"Baseline_1500s\"\n",
    "baseline_2500s_data_payoff$group <- \"Baseline_2500s\"\n",
    "payoff_1500s_data$group <- \"Payoff_1500s\"\n",
    "payoff_2500s_data$group <- \"Payoff_2500s\"\n",
    "\n",
    "data_1500s_payoff <- bind_rows(baseline_1500s_data_payoff, payoff_1500s_data) %>%\n",
    "  mutate(Subject = paste0(group, \"_\", Subject)) %>%\n",
    "  arrange(Subject, Round, Phase)\n",
    "\n",
    "data_2500s_payoff <- bind_rows(baseline_2500s_data_payoff, payoff_2500s_data) %>%\n",
    "  mutate(Subject = paste0(group, \"_\", Subject)) %>%\n",
    "  arrange(Subject, Round, Phase)\n",
    "\n",
    "# Panel A: Average Performance Per Round in 1500s\n",
    "performance_by_round_1500s_payoff <- data_1500s_payoff %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_performance = mean(performance, na.rm = TRUE),\n",
    "    se_performance = sd(performance, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p11 <- ggplot(performance_by_round_1500s_payoff, aes(x = Round, y = mean_performance, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_performance - se_performance, ymax = mean_performance + se_performance), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline_1500s\" = \"#1F77B4\", \"Payoff_1500s\" = \"#FF7F0E\")) +\n",
    "  labs(title = \"Performance in 1500s ('High-Payoff' Strategy vs Baseline)\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Compare Payoff_1500s with Baseline_1500s performance\n",
    "baseline_1500s_performance_payoff <- data_1500s_payoff %>% filter(group == \"Baseline_1500s\") %>% select(performance)\n",
    "payoff_1500s_performance <- data_1500s_payoff %>% filter(group == \"Payoff_1500s\") %>% select(performance)\n",
    "p_payoff_1500s <- wilcox_test(baseline_1500s_performance_payoff$performance, payoff_1500s_performance$performance, \"two.sided\")\n",
    "cat(\"Payoff_1500s vs Baseline_1500s (two-sided test): p =\", p_payoff_1500s, \"\\n\")\n",
    "\n",
    "# Display the plot\n",
    "print(p11)\n",
    "ggsave(\"perform_1500S_PayoffvsBaseline.png\", p11, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel B: Average Performance Per Round in 2500s\n",
    "performance_by_round_2500s_payoff <- data_2500s_payoff %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_performance = mean(performance, na.rm = TRUE),\n",
    "    se_performance = sd(performance, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p12 <- ggplot(performance_by_round_2500s_payoff, aes(x = Round, y = mean_performance, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_performance - se_performance, ymax = mean_performance + se_performance), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline_2500s\" = \"#1F77B4\", \"Payoff_2500s\" = \"#FF7F0E\")) +\n",
    "  labs(title = \"Performance in 2500s ('High-Payoff' Strategy vs Baseline)\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p12)\n",
    "ggsave(\"perform_2500S_PayoffvsBaseline.png\", p12, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel C: AC Distribution Per Round (Bubble Plot)\n",
    "ac_freq_payoff <- data_1500s_payoff %>%\n",
    "  filter(Round <= 5) %>%\n",
    "  group_by(group, Round, AC) %>%\n",
    "  summarise(count = n(), .groups = \"drop\") %>%\n",
    "  filter(!is.na(AC))\n",
    "p13 <- ggplot(ac_freq_payoff, aes(x = Round, y = AC, size = count, color = group)) +\n",
    "  geom_point(position = position_dodge(width = 0.8), alpha = 0.7) +\n",
    "  scale_size_continuous(range = c(2, 10)) +\n",
    "  scale_color_manual(values = c(\"Baseline_1500s\" = \"#1F77B4\", \"Payoff_1500s\" = \"#FF7F0E\")) +\n",
    "  labs(title = \"Accuracy Distribution ('High-Payoff' vs Baseline)\", x = \"Round\", y = \"Accuracy\", size = \"Number\", color = \"Group\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p13)\n",
    "ggsave(\"AC_1500S_PayoffvsBaseline.png\", p13, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine plots for Payoff vs Baseline\n",
    "combined_plot_payoff <- ggarrange(p11, p13,\n",
    "                                  labels = c(\"A\", \"B\"),\n",
    "                                  ncol = 2, nrow = 1,\n",
    "                                  heights = c(1, 1),\n",
    "                                  common.legend = FALSE)\n",
    "ggsave(\"combined_analysis_PayoffvsBaseline.png\", combined_plot_payoff, width = 10, height = 6, dpi = 300)\n",
    "\n",
    "# Display the combined plot\n",
    "print(combined_plot_payoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: WSLS vs Payoff Analysis\n",
    "\n",
    "This section compares WSLS, Payoff, and Integration strategies against the Baseline over 1500s and 2500s, focusing on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1500s Data loading\n",
    "baseline_1500s_data_wsls_payoff <- read_csv(\"baseline_1500s_allresult_processed.csv\")\n",
    "WSLS_1500s_data <- read_csv(\"WSLS_1500s_allresult_processed.csv\")\n",
    "payoff_1500s_data_wsls <- read_csv(\"payoff_1500s_allresult_processed.csv\")\n",
    "integration_1500s_data <- read_csv(\"integration_1500s_allresult_processed.csv\")\n",
    "\n",
    "baseline_1500s_data_wsls_payoff <- baseline_1500s_data_wsls_payoff %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "WSLS_1500s_data <- WSLS_1500s_data %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "payoff_1500s_data_wsls <- payoff_1500s_data_wsls %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "integration_1500s_data <- integration_1500s_data %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "\n",
    "baseline_1500s_data_wsls_payoff$group <- \"Baseline_1500s\"\n",
    "WSLS_1500s_data$group <- \"WSLS_1500s\"\n",
    "payoff_1500s_data_wsls$group <- \"Payoff_1500s\"\n",
    "integration_1500s_data$group <- \"Integration_1500s\"\n",
    "\n",
    "all_data_1500s_wsls_payoff <- bind_rows(baseline_1500s_data_wsls_payoff, WSLS_1500s_data, payoff_1500s_data_wsls, integration_1500s_data) %>%\n",
    "  mutate(Subject = paste0(group, \"_\", Subject)) %>%\n",
    "  arrange(Subject, Round, Phase)\n",
    "\n",
    "# Panel A: Average Performance Per Round in 1500s\n",
    "performance_by_round_1500s_wsls_payoff <- all_data_1500s_wsls_payoff %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_performance = mean(performance, na.rm = TRUE),\n",
    "    se_performance = sd(performance, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p14 <- ggplot(performance_by_round_1500s_wsls_payoff, aes(x = Round, y = mean_performance, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_performance - se_performance, ymax = mean_performance + se_performance), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline_1500s\" = \"#1F77B4\", \"WSLS_1500s\" = \"#FF7F0E\", \"Payoff_1500s\" = \"#2CA02C\", \"Integration_1500s\" = \"#D62728\")) +\n",
    "  labs(title = \"Performance of Different Adaptive Strategies in 1500s\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p14)\n",
    "ggsave(\"perform_WSLSvsPayoff_1500s.png\", p14, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2500s Data loading\n",
    "baseline_2500s_data_wsls_payoff <- read_csv(\"baseline_2500s_allresult_processed.csv\")\n",
    "WSLS_2500s_data <- read_csv(\"WSLS_2500s_allresult_processed.csv\")\n",
    "payoff_2500s_data_wsls <- read_csv(\"payoff_2500s_allresult_processed.csv\")\n",
    "integration_2500s_data <- read_csv(\"integration_2500s_allresult_processed.csv\")\n",
    "\n",
    "baseline_2500s_data_wsls_payoff <- baseline_2500s_data_wsls_payoff %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "WSLS_2500s_data <- WSLS_2500s_data %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "payoff_2500s_data_wsls <- payoff_2500s_data_wsls %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "integration_2500s_data <- integration_2500s_data %>%\n",
    "  select(-Schema, -schema_payoff)\n",
    "\n",
    "baseline_2500s_data_wsls_payoff$group <- \"Baseline_2500s\"\n",
    "WSLS_2500s_data$group <- \"WSLS_2500s\"\n",
    "payoff_2500s_data_wsls$group <- \"Payoff_2500s\"\n",
    "integration_2500s_data$group <- \"Integration_2500s\"\n",
    "\n",
    "all_data_2500s_wsls_payoff <- bind_rows(baseline_2500s_data_wsls_payoff, WSLS_2500s_data, payoff_2500s_data_wsls, integration_2500s_data) %>%\n",
    "  mutate(Subject = paste0(group, \"_\", Subject)) %>%\n",
    "  arrange(Subject, Round, Phase)\n",
    "\n",
    "# Panel B: Average Performance Per Round in 2500s\n",
    "performance_by_round_2500s_wsls_payoff <- all_data_2500s_wsls_payoff %>%\n",
    "  group_by(group, Round) %>%\n",
    "  summarise(\n",
    "    mean_performance = mean(performance, na.rm = TRUE),\n",
    "    se_performance = sd(performance, na.rm = TRUE) / sqrt(n())\n",
    "  )\n",
    "p15 <- ggplot(performance_by_round_2500s_wsls_payoff, aes(x = Round, y = mean_performance, color = group)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_ribbon(aes(ymin = mean_performance - se_performance, ymax = mean_performance + se_performance), alpha = 0.08, linetype = 0) +\n",
    "  scale_color_manual(values = c(\"Baseline_2500s\" = \"#1F77B4\", \"WSLS_2500s\" = \"#FF7F0E\", \"Payoff_2500s\" = \"#2CA02C\", \"Integration_2500s\" = \"#D62728\")) +\n",
    "  labs(title = \"Performance of Different Adaptive Strategies in 2500s\", x = \"Round\", y = \"Average Performance Score\") +\n",
    "  theme_minimal(base_size = 12) +\n",
    "  theme(legend.position = \"top\", plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"))\n",
    "\n",
    "# Display the plot\n",
    "print(p15)\n",
    "ggsave(\"perform_WSLSvsPayoff_2500s.png\", p15, width = 8, height = 7, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine plots for WSLS vs Payoff\n",
    "combined_plot_wsls_payoff <- ggarrange(p14, p15,\n",
    "                                       labels = c(\"A\", \"B\"),\n",
    "                                       ncol = 2, nrow = 1,\n",
    "                                       heights = c(1, 1),\n",
    "                                       common.legend = FALSE)\n",
    "ggsave(\"combined_analysis_WSLSvsPayoff.png\", combined_plot_wsls_payoff, width = 10, height = 6, dpi = 300)\n",
    "\n",
    "# Display the combined plot\n",
    "print(combined_plot_wsls_payoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}